{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Headlines About Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up spliner variables. Make it headless so it doesn't open a browser each time.\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "# Send it to the nasa site\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the browser's webpage to html and turn it into soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first title and body\n",
    "news_title = soup.find(\"div\", class_=\"list_text\").find(\"div\", class_=\"content_title\").text\n",
    "news_p = soup.find(\"div\", class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The Extraordinary Sample-Gathering System of NASA's Perseverance Mars Rover\nTwo astronauts collected Moon rocks on Apollo 11. It will take three robotic systems working together to gather up the first Mars rock samples for return to Earth.\n"
    }
   ],
   "source": [
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Nasa's Featured Mars Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it again for the images\n",
    "url_base = \"https://www.jpl.nasa.gov\"\n",
    "url = url_base+\"/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into soup! \n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image is in a style tag, so let's grab that. \n",
    "bg_img = soup.find(\"article\", class_=\"carousel_item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17932-1920x1200.jpg\n"
    }
   ],
   "source": [
    "# Now let's split it out of the style tag\n",
    "# Convert it to a string, and split it on the ' around the url\n",
    "image = (str(bg_img)).split(\"('\", 1)[1].split(\"')\")[0]\n",
    "\n",
    "# Get a full url by combining it with the base url\n",
    "featured_image_url = url_base+image\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Weather on Mars from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into soup! \n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_article = soup.find(\"article\", {\"role\" : \"article\", \"tabindex\":0})\n",
    "spans = tweet_article.find_all(\"span\")\n",
    "for span in spans:\n",
    "    if span.text[0:7] == \"InSight\":\n",
    "        mars_weather = span.text\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "InSight sol 543 (2020-06-06) low -92.9ºC (-135.3ºF) high -6.6ºC (20.2ºF)\nwinds from the WNW at 7.2 m/s (16.0 mph) gusting to 21.0 m/s (47.0 mph)\npressure at 7.40 hPa\n"
    }
   ],
   "source": [
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing some Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://space-facts.com/mars/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all('table')[0] \n",
    "df = pd.read_html(str(table))\n",
    "# df = df[0]\n",
    "# mars_info_table = df.to_html(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[                      0                              1\n 0  Equatorial Diameter:                       6,792 km\n 1       Polar Diameter:                       6,752 km\n 2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n 3                Moons:            2 (Phobos & Deimos)\n 4       Orbit Distance:       227,943,824 km (1.38 AU)\n 5         Orbit Period:           687 days (1.9 years)\n 6  Surface Temperature:                   -87 to -5 °C\n 7         First Record:              2nd millennium BC\n 8          Recorded By:           Egyptian astronomers]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the base url to add to the img url later\n",
    "url_base = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# Create a list of urls to scrape through\n",
    "url_list = [\"https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\", \"https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced\", \"https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced\", \"https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced\"]\n",
    "\n",
    "# Create an empty list to store each image url in\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Go through the different urls and scrape what is needed. Add to a dictionary and append to the list. \n",
    "for url in url_list:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Grab the title of the image\n",
    "    title = soup.find(\"h2\", class_=\"title\").text\n",
    "    # Create the full image url by combining the url base with the image url\n",
    "    img = url_base + (soup.find(\"img\", class_=\"wide-image\")[\"src\"])\n",
    "    # Create a dictionary of the title and the url\n",
    "    img_dict = {\n",
    "        \"title\" : title,\n",
    "        \"image_url\" : img\n",
    "    }\n",
    "    # Throw that dictionary into a list for parsing later. \n",
    "    hemisphere_image_urls.append(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'title': 'Cerberus Hemisphere Enhanced',\n  'image_url': 'https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg'},\n {'title': 'Schiaparelli Hemisphere Enhanced',\n  'image_url': 'https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg'},\n {'title': 'Syrtis Major Hemisphere Enhanced',\n  'image_url': 'https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg'},\n {'title': 'Valles Marineris Hemisphere Enhanced',\n  'image_url': 'https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg'}]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}